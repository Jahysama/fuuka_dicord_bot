{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fuuka.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlWC0Ox1PCbg",
        "outputId": "24032add-cfdf-4f2c-be2a-cab356034dcd"
      },
      "source": [
        "!pip install discord.py\n",
        "!pip install nest_asyncio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: discord.py in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Requirement already satisfied: aiohttp<3.7.0,>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from discord.py) (3.6.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py) (3.0.1)\n",
            "Requirement already satisfied: yarl<1.6.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py) (1.5.1)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py) (1.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py) (20.3.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py) (3.0.4)\n",
            "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py) (4.7.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py) (3.7.4.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.6/dist-packages (from yarl<1.6.0,>=1.0->aiohttp<3.7.0,>=3.6.0->discord.py) (2.10)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.6/dist-packages (1.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dXookZfOqHI"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjW8_0PONYhN",
        "outputId": "da63adf7-3fcf-4c68-fd00-2ea09af294db"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "import os\n",
        "sample_dir = 'Anime'\n",
        "os.makedirs(sample_dir, exist_ok=True)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHU-rH1qaM5v"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    #np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdh_Tsccfl3O"
      },
      "source": [
        "def convert_to_int(string):\n",
        "  out = ''.join(str(ord(c)) for c in string)\n",
        "  return int(out)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXlrGJ9VOJhx"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE9m8EqbOy5Q"
      },
      "source": [
        "latent_size = 512\n",
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "    nn.ConvTranspose2d(latent_size, 2048, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(2048),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(2048, 1024, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 64 x 64\n",
        ")\n",
        "generator.load_state_dict(torch.load('gdrive/MyDrive/Models/epoch_new-5.pt'))\n",
        "generator.eval()\n",
        "\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "def denorm(img_tensors):\n",
        "    return img_tensors * stats[1][0] + stats[0][0]\n",
        "def save_sample(file_name, latent_tensors):\n",
        "    fake_images = generator(latent_tensors)[0]\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, file_name))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1WYi7vwOMUj",
        "outputId": "967c0ac1-c689-490e-eb8c-7221fbcd477f"
      },
      "source": [
        "device = get_default_device()\n",
        "generator = to_device(generator, device)\n",
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlqRRX_BMO3s"
      },
      "source": [
        "import discord\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "async def main():\n",
        "  TOKEN = 'INSERT YOUR TOKEN HERE'\n",
        "\n",
        "  #client = discord.Client()\n",
        "\n",
        "  from discord.ext import commands\n",
        "\n",
        "  bot = commands.Bot(command_prefix='<', help_command=None)\n",
        "\n",
        "\n",
        "  @bot.event\n",
        "  async def on_ready():\n",
        "     print('Ready')\n",
        "\n",
        "  @bot.command(pass_context=True)\n",
        "  @commands.cooldown(4, 1, commands.BucketType.user)\n",
        "  async def help(ctx):\n",
        "\n",
        "      embed = discord.Embed(\n",
        "          colour=discord.Colour.from_rgb(153, 102, 51),\n",
        "          title=\"Fuuka\",\n",
        "          description=\"Deep learning shit bot\"\n",
        "      )\n",
        "\n",
        "      #embed.set_author(name=\"Author\", icon_url=\"https://cdn.discordapp.com/attachments/755435067282555011/781253419486150666/fuuka.png\")\n",
        "      #embed.set_image(url=\"https://cdn.discordapp.com/attachments/755435067282555011/781254299908702208/puuka.png\")\n",
        "      embed.set_thumbnail(url=\"https://cdn.discordapp.com/attachments/755435067282555011/781254299908702208/puuka.png\")\n",
        "      embed.add_field(name=\"ping\", value=\"This has the bot say pong\", inline=False)\n",
        "      embed.add_field(name=\"cum\", value=\"Allows to cum on someone.\\n Usage: cum <USER NAME>\", inline=False)\n",
        "      embed.add_field(name=\"help\", value=\"Calls help\", inline=False)\n",
        "      embed.add_field(name=\"anime\", value=\"Generates anime picture\\n Usage: anime <optional_seed>\", inline=False)\n",
        "      embed.set_footer(text='Fuuka is a \"Yotsubato!\" manga character')\n",
        "\n",
        "      await ctx.send(embed=embed)\n",
        "\n",
        "\n",
        "  @bot.command(name=\"ping\", description=\"pong\")\n",
        "  @commands.cooldown(4, 1, commands.BucketType.user)\n",
        "  async def ping(ctx):\n",
        "    await ctx.send('Pong! {0}'.format(round(bot.latency, 6)))\n",
        "\n",
        "  @bot.command(name=\"anime\", description=\"Post generated anime picture\")\n",
        "  @commands.cooldown(4, 1, commands.BucketType.user)\n",
        "  async def anime(ctx, seed = None):\n",
        "    seed_str = str(seed)\n",
        "    if seed != None:\n",
        "      seed_everything(convert_to_int(seed_str))\n",
        "\n",
        "    rand = torch.randn(1, latent_size, 2, 2, device=device) # random latent tensors\n",
        "    save_sample('example.png', rand)\n",
        "    await ctx.send(file=discord.File('Anime/example.png'))\n",
        "    \n",
        "\n",
        "  @bot.command(name=\"cum\", description=\"Allows to cum on someone. Usage: cum <USER NAME>\")\n",
        "  @commands.cooldown(4, 1, commands.BucketType.user)\n",
        "  async def cum(ctx, username = None):\n",
        "    guy = ctx.message.author.display_name\n",
        "    if username == None:\n",
        "        await ctx.send('{} cummed inside yourself'.format(guy))\n",
        "        return\n",
        "    slut = username\n",
        "    await ctx.send('{} cummed on {}'.format( guy, slut))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  @ping.error\n",
        "  @cum.error\n",
        "  @anime.error\n",
        "  async def error(ctx, error):\n",
        "    if isinstance(error, commands.CommandOnCooldown):\n",
        "        msg = 'Coldown'.format(error.retry_after)\n",
        "        await ctx.send(msg, delete_after=1) \n",
        "    else:\n",
        "        raise error\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "  bot.run(TOKEN)\n",
        "\n",
        "\n",
        "asyncio.run(main())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
